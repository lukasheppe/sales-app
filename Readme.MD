# Readme

Die Sales-App ermöglicht es Nutzern, Lizenzen zu kaufen. Die App besteht aus den folgenden, vier Komponenten:

- Datenbank
- Backend
- Frontend
- Reverse-Proxy

Jede der Komponenten ist in einem Container verpackt. Vernetzt sind die einzelnen Services durch ein Dockernetzwerk. Nutzer können mit den Services nur durch den Proxy
kommunizieren.

## Struktur

### Datenbank

Zur Datenspeicherung wird eine [Postgres-Datenbank](https://www.postgresql.org/) eingesetzt. Um die Persistenz der Daten zu ermöglichen, wird ein Docker-Volume verwendet.

### Backend

Das Backend wurde mit [FastAPI](https://fastapi.tiangolo.com/) realisiert. Es stehen drei Endpunkte zur Verfügung:

- `GET /api/get_current_money`: Anzahl an Verkäufen und totaler Umsatz.
- `POST /api/buy_mpi`: Kauf einer Lizenz
- `DELETE /api/sales`: Lösche den Inhalt der Sales-Tabelle

### Frontend

Das Frontend besteht aus den beiden HTML-Seiten `index.html` und `sales.html`. Diese werden von einem [Nginx-Webserver](https://www.nginx.com/) gehostet. Auf der `index.html` können
Nutzer eine von drei möglichen Lizenzen erwerben. Sobald der Nutzer auf einen Button klickt, wird ein Request an das Backend gestellt. Auf der `sales.html` kann das Salesteam die
Anzahl an Transaktionen sowie das Transaktionsvolumen einsehen.

### Reverse-Proxy

Als Reverse-Proxy wird [Traefik](https://traefik.io/) eingesetzt. Der Proxy bezeichnet sich als "Cloud-Native" und ist in der Lage, Ressourcen, welche im Swarm bereitgestellt
werden, automatisch (basierend auf Container-Labeln) zu erkennen und das Load-Balancing zu übernehmen. Nutzer stellen ihre Anfragen an den Proxy, welcher diese dann an die
entsprechenden Services im Netzwerk weiterleitet. Falls die Development-Compose-Datei ```docker-compose.yml``` genutzt wird, kann ebenfalls
das [pgAdmin-Tool](https://www.pgadmin.org/)  unter
```pgadmin.localhost``` abgerufen werden. Folgende Regeln gelten:

### Proxy Rules / URLS

- Verkaufsseite: ```localhost[/index.html]```
- Salesübersicht: ```localhost/sales.html```
- PGAdmin (Dev): ```pgadmin.localhost```
- Backend API: ```sales.localhost```
- Backend API (generated by Swagger): ```sales.localhost/docs```
- Proxy-Dashboard: ```localhost:8080```

---------------------------------------------------------------------------------------------------------

## Setup guide

### Development

Während des Developments werden die Container lokal gebaut.

```bash
docker-compose up --build --force-recreate
```

### Deployment

Für das Deployment werden die Container von einer [GitHub-Action](.github/workflows/image.yml) gebaut und in die DockerHub Registry gepusht.

```bash
docker-compose -f docker-compose-deploy.yml up
```

---------------------------------------------------------------------------------------------------------

## Wie sieht das Deployment für 10 Nutzer aus?

Zehn Nutzer pro Stunde können einfach vom aktuellen Setup bedient werden. Außerdem können die einzelnen Komponenten, außer der Datenbank, bereits innerhalb des Containers skaliert
werden, beispielsweise indem die Anzahl der Worker für den NGINX oder die Prozessanzahl des Gunicorn API-Servers angepasst wird.

## Wie würde das Deployment für 10 Tsd. und 10 Mio. Nutzer (pro Stunde) aussehen?

Sollte doch ein höheres Datenvolumen auftreten, könnte die App statt auf einem einzelnen Node in einem Swarmcluster ausgeführt werden. Dazu muss ein Swarmcluster mit mehreren Nodes
aufgesetzt werden. Anschließend kann die Anwendung über das folgende Kommando als Service/Stack erstellt und komponentenweise skaliert werden:

```bash
# Verifizierung der compose Datei.
docker-compose -f docker-compose-deploy.yml config

# Deployment des Stacks
docker stack deploy --compose-file docker-compose.yml mystackname

# Scaling eines Services (z.B. 5 Replikas des Backend)
docker service scale mystackname_backend=5
```

Sollte dieser Ansatz nicht ausreichen, könnten mehrere Cluster (auch in verschiedenen Regionen) betrieben werden und die Anfragen an diese per DNS-Round Robin oder Any-Cast
(möglicherweise sogar eine Kombination dieser Techniken) geroutet werden. Außerdem wäre es denkbar, die App in die Komponenten Front- und Backend zu zerlegen, so dass diese
Services jeweils auf Hardware laufen, die optimal für die Anforderungen sind. Außerdem könnten Techniken wie Auto-Scaling verwendet werden, welche automatisch, basierend auf der
Last, Container starten und beenden.

Ein besonderes Augenmerk sollte auf der Skalierung der Datenbank liegen, da diese in einem persistenten Zustand verweilen muss und dies in der aktuellen Implementierung mit
Docker-Volumes nicht berücksichtigt wurde. Techniken zu High Availabilty und Failover sind [hier](https://www.postgresql.org/docs/9.5/high-availability.html) dokumentiert.

## Wie kann Ausfallsicherheit gewährleistet werden?

Um Ausfallsicherheit zu gewährleisten, sollte ein Single Point of Failure vermieden werden. Dazu können mehrere Replikas eines Services erstellt werden, so dass falls ein Service
ausfällt, die Anfragen an eine andere Instanz dieses weitergeleitet werden. Dazu müssten die Services Health-Checks definieren, über welche z.B. ein Proxy / Load-Balancer
entscheiden kann, ob der Service bereit ist, Anfragen zu empfangen. Außerdem sollte ein High Availability-Proxy genutzt werden, so dass auch dieser gegen Ausfälle gesichert ist.

## Welche Analysemöglichkeiten gäbe es?

Zur Analyse bieten sich verschiedene Möglichkeiten. Zunächst könnten die einzelnen Nodes/Cluster über ein Monitoring-System überwacht werden. Dies kann dem Betreiber einen Einblick
über den Resourcenverbrauch der Services geben. Somit kann der Betrieber einschätzen, ob er ausreichend oder zu viel Hardware bereitstellt. Basierend auf diesen Einblicken könnte
die Infrasturktur sklaliert werden, um Kosten bei Cloudanbietern oder lokale Stromkosten zu reduzieren.

Anschließend könnten z.B. Anfragen simuliert werden, um die Latenz des Systems unter verschiedenen Lasten zu analysieren. Mit den erhobeben Daten könnten Empfehlungen ausgesprochen
werden, wie viele Services laufen sollten, wenn z.B. aktuell 1.000.0000 Anfragen auftreten. Außerdem können so die Belastbarkeitsgrenzen der aktuellen Infrastruktur ausgetestet
werden. Des Weiteren ist es interessant, sich die Auslastung der individuellen Services anzuschauen, da ein Frontend möglicherweise mehr Nutzer als ein Backend bedienen kann. Mit
dieser Information könnten die einzelnen Komponenten unterschiedlich skaliert werden.

Ein weiterer Aspekt, der betrachtet werden kann, ist die Container Startup Time. Falls viele Container auf unterschiedlichen Hosts gestartet werden müssen, sollten die Images
möglichst klein sein, um sowohl Downloadzeiten und damit den Bandbreitenverbrauch zu minimieren. Ebenso sollte die Uptime der Anwendung überwacht werden und im Falle von
ausfallenden Komponenten eine Ursachenforschung betrieben werden, um dies in Zukunft zu vermeiden. Genauso interessant ist die Mean Time To Repair sowie andere
verwandte [Metriken](https://www.splunk.com/en_us/data-insider/what-is-mean-time-to-repair.html).
